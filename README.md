# Word-level language modeling for Wikitext dataset using Recurrent Neural Networks

This model trains a multi-layer RNN (Elman, GRU, or LSTM) on a language modeling task.
By default, the training script uses the Wikitext-2 dataset, provided.
The trained model can then be used by the generate script to generate new text.
For dataset, check https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/
